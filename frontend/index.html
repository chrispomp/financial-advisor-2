<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Citi AI Wealth Advisor</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <style>
        :root { --primary-blue: #003B70; --primary-red: #D9261C; --neutral-bg: #FFFFFF; --neutral-light-gray: #F0F2F5; --status-green: #28a745; --font-family: 'Helvetica Neue', Arial, sans-serif; }
        body { background-color: var(--neutral-light-gray); font-family: var(--font-family); margin: 0; padding: 20px; display: flex; justify-content: center; align-items: center; min-height: 100vh; }
        .mobile-container { width: 100%; max-width: 400px; height: 85vh; max-height: 750px; background-color: var(--neutral-bg); border-radius: 20px; box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1); overflow: hidden; display: flex; flex-direction: column; }
        header { padding: 15px 20px; background-color: var(--primary-blue); text-align: center; flex-shrink: 0; }
        header img { height: 30px; }
        main { flex-grow: 1; position: relative; background-color: #000; display: flex; flex-direction: column; justify-content: space-between; }
        .agent-view { position: relative; width: 100%; flex-grow: 1; display: flex; flex-direction: column; justify-content: center; align-items: center; }
        .agent-placeholder { text-align: center; color: #ccc; }
        .agent-placeholder i { font-size: 80px; margin-bottom: 20px; }
        .agent-placeholder.active i { color: var(--primary-blue); animation: pulse 2s infinite; }
        @keyframes pulse { 0% { transform: scale(1); } 50% { transform: scale(1.1); } 100% { transform: scale(1); } }
        #agent-transcript { position: absolute; bottom: 20px; left: 20px; right: 20px; background: rgba(0, 0, 0, 0.5); color: white; padding: 15px; border-radius: 10px; text-align: center; font-size: 1.1em; min-height: 50px; display: flex; align-items: center; justify-content: center; }
        .status-overlay { position: absolute; top: 10px; left: 10px; background-color: rgba(0, 0, 0, 0.5); color: white; padding: 5px 10px; border-radius: 15px; font-size: 14px; display: flex; align-items: center; }
        .status-dot { width: 10px; height: 10px; border-radius: 50%; background-color: var(--primary-red); margin-right: 8px; }
        .status-dot.connected { background-color: var(--status-green); }
        .controls { padding: 20px; background-color: #000; display: flex; justify-content: center; gap: 20px; flex-shrink: 0; }
        .control-button { width: 60px; height: 60px; border-radius: 50%; border: none; cursor: pointer; font-size: 24px; color: white; display: flex; justify-content: center; align-items: center; transition: background-color 0.2s; }
        #startStopBtn { background-color: var(--primary-blue); }
        #startStopBtn.active { background-color: var(--primary-red); }
        #muteBtn { background-color: rgba(255, 255, 255, 0.3); }
        #muteBtn:disabled { background-color: rgba(255, 255, 255, 0.1); cursor: not-allowed; }
    </style>
</head>
<body>
    <div class="mobile-container">
        <header><img src="https://www.citi.com/mobile-apps/assets/img/citi-logo-white.svg" alt="Citi Logo"></header>
        <main>
            <div class="agent-view">
                <div class="agent-placeholder" id="agent-placeholder">
                    <i class="fa-solid fa-brain"></i>
                    <p>Session not started</p>
                </div>
                <div id="agent-transcript"><p>...</p></div>
                <div class="status-overlay">
                    <div id="status-dot" class="status-dot"></div><span id="status-text">Disconnected</span>
                </div>
            </div>
            <div class="controls">
                <button id="muteBtn" class="control-button" disabled><i class="fa-solid fa-microphone"></i></button>
                <button id="startStopBtn" class="control-button"><i class="fa-solid fa-phone"></i></button>
            </div>
        </main>
    </div>

    <script>
        const ui = {
            startStopBtn: document.getElementById('startStopBtn'),
            muteBtn: document.getElementById('muteBtn'),
            statusText: document.getElementById('status-text'),
            statusDot: document.getElementById('status-dot'),
            placeholder: document.getElementById('agent-placeholder'),
            transcript: document.getElementById('agent-transcript'),
        };

        const initialState = {
            isConversationActive: false,
            isMuted: false,
            localStream: null,
            socket: null,
            audioContext: null,
            audioProcessor: null,
            audioPlayer: null,
            transcriptText: '',
        };

        let state = { ...initialState };

        const serverUrl = 'http://localhost:8000';

        ui.startStopBtn.addEventListener('click', () => state.isConversationActive ? endConversation() : startConversation());
        ui.muteBtn.addEventListener('click', toggleMute);

        // --- Core Conversation Logic ---

        async function startConversation() {
            try {
                // Request audio only, aligning with API capabilities
                const stream = await navigator.mediaDevices.getUserMedia({ video: false, audio: { sampleRate: 16000, channelCount: 1 } });
                
                state.localStream = stream;
                ui.placeholder.classList.add('active');
                ui.placeholder.querySelector('p').textContent = 'Connecting...';

                await connectToAgent(stream);

                state.isConversationActive = true;
                ui.startStopBtn.classList.add('active');
                ui.startStopBtn.querySelector('i').className = 'fa-solid fa-phone-slash';
                ui.muteBtn.disabled = false;
                ui.placeholder.querySelector('p').textContent = 'Listening...';
            } catch (error) {
                console.error("âŒ Failed to start conversation:", error);
                alert("Could not start. Check console for errors.");
                endConversation();
            }
        }

        function endConversation() {
            state.localStream?.getTracks().forEach(track => track.stop());
            state.socket?.close();
            state.audioContext?.close();
            
            ui.placeholder.classList.remove('active');
            ui.placeholder.querySelector('p').textContent = 'Session ended';
            ui.statusText.textContent = 'Disconnected';
            ui.statusDot.classList.remove('connected');
            ui.transcript.innerHTML = '<p>...</p>';

            // Reset state object
            state = { ...initialState };

            ui.startStopBtn.classList.remove('active');
            ui.startStopBtn.querySelector('i').className = 'fa-solid fa-phone';
            ui.muteBtn.disabled = true;
            ui.muteBtn.querySelector('i').className = 'fa-solid fa-microphone';
        }

        // --- Network and Media Setup ---

        function connectToAgent(stream) {
            return new Promise(async (resolve, reject) => {
                const wsUrl = serverUrl.replace('http', 'ws');
                state.socket = new WebSocket(`${wsUrl}/run_live`);
                state.socket.binaryType = "arraybuffer";

                state.socket.onopen = async () => {
                    console.log("âœ… WebSocket connected. Initializing audio processor.");
                    ui.statusText.textContent = 'Connected';
                    ui.statusDot.classList.add('connected');
                    try {
                        await setupAudio(stream);
                        resolve();
                    } catch (e) { reject(e); }
                };

                state.socket.onmessage = handleAgentMessage;
                state.socket.onerror = (err) => { console.error("âŒ WebSocket Error:", err); reject(err); };
                state.socket.onclose = () => { console.log("ðŸ”Œ WebSocket closed."); if(state.isConversationActive) endConversation(); };
            });
        }

        async function setupAudio(stream) {
            // The API output is 24kHz, so we should set our context to that for proper playback.
            state.audioContext = new AudioContext({ sampleRate: 24000 });

            // Setup audio recorder (sends 16kHz audio from microphone)
            const source = state.audioContext.createMediaStreamSource(stream);
            const recorderWorklet = new AudioWorkletNode(state.audioContext, 'audio-processor');
            source.connect(recorderWorklet);
            recorderWorklet.port.onmessage = event => {
                if (state.socket && state.socket.readyState === WebSocket.OPEN) {
                    state.socket.send(event.data);
                }
            };
            // We need to load the module for the recorder before we can create the node
            await state.audioContext.audioWorklet.addModule('audio-processor.js');


            // Setup audio player (receives 24kHz audio from agent)
            await state.audioContext.audioWorklet.addModule('audio-player.js');
            state.audioPlayer = new AudioWorkletNode(state.audioContext, 'audio-player-processor');
            state.audioPlayer.connect(state.audioContext.destination);
        }

        // --- Agent Message Handling ---

        function handleAgentMessage(event) {
            if (event.data instanceof ArrayBuffer) {
                // This is an audio chunk, send it to the player
                state.audioPlayer.port.postMessage({ pcmData: new Int16Array(event.data) });
                return;
            }
            
            // This is a JSON message
            const message = JSON.parse(event.data);
            console.log("Agent Message:", message);

            // Handle transcription updates
            if (message.server_content && message.server_content.output_transcription) {
                const newText = message.server_content.output_transcription.text;
                if (newText) {
                    state.transcriptText = newText;
                    ui.transcript.innerHTML = `<p>${state.transcriptText}</p>`;
                }
            }

            // When the model turn is complete, clear the transcript for the next turn
            if (message.server_content && message.server_content.turn_complete) {
                state.transcriptText = '';
            }
        }
        
        // --- Utility Functions ---

        function toggleMute() {
            if (!state.localStream) return;
            state.isMuted = !state.isMuted;
            state.localStream.getAudioTracks()[0].enabled = !state.isMuted;
            ui.muteBtn.querySelector('i').className = state.isMuted ? 'fa-solid fa-microphone-slash' : 'fa-solid fa-microphone';
        }
    </script>
</body>
</html>